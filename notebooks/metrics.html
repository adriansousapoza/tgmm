

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Clustering Metrics: Comprehensive Evaluation of Gaussian Mixture Models &mdash; TorchGMM 0.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css?v=2aa19091" />
      <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=5c7ff671" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=01f34227"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
      <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "displayMath": [["$$", "$$"], ["\\[", "\\]"]]}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Priors in Gaussian Mixture Models" href="priors.html" />
    <link rel="prev" title="Gaussian Mixture Model (GMM) Usage, Analysis and Visualization" href="gmm.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            TorchGMM
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../source/modules.html">Modules</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../source/tutorials.html">Tutorials</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="gmm.html">Gaussian Mixture Model (GMM) Usage, Analysis and Visualization</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Clustering Metrics: Comprehensive Evaluation of Gaussian Mixture Models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Synthetic-Data-Generation">Synthetic Data Generation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Unsupervised-Clustering-Metrics-Definitions">Unsupervised Clustering Metrics Definitions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Silhouette-Score">Silhouette Score</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Davies-Bouldin-Index">Davies-Bouldin Index</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Calinski-Harabasz-Score">Calinski-Harabasz Score</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Dunn-Index">Dunn Index</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Bayesian-Information-Criterion-(BIC)">Bayesian Information Criterion (BIC)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Akaike-Information-Criterion-(AIC)">Akaike Information Criterion (AIC)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Supervised-Clustering-Metrics-Definitions">Supervised Clustering Metrics Definitions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Rand-Index-(RI)">Rand Index (RI)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Adjusted-Rand-Index-(ARI)">Adjusted Rand Index (ARI)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Mutual-Information-(MI)">Mutual Information (MI)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Normalized-Mutual-Information-(NMI)">Normalized Mutual Information (NMI)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Adjusted-Mutual-Information-(AMI)">Adjusted Mutual Information (AMI)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Fowlkes-Mallows-Index-(FMI)">Fowlkes-Mallows Index (FMI)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Homogeneity-and-Completeness">Homogeneity and Completeness</a></li>
<li class="toctree-l4"><a class="reference internal" href="#V-Measure">V-Measure</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Purity">Purity</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Model-Comparison:-TorchGMM-vs-Scikit-learn">Model Comparison: TorchGMM vs Scikit-learn</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Metrics-Comparison-Table">Metrics Comparison Table</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Confusion-Matrix-and-Classification-Report">Confusion Matrix and Classification Report</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Understanding-the-Confusion-Matrix">Understanding the Confusion Matrix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#KL-Divergence-Analysis">KL Divergence Analysis</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Kullback-Leibler-Divergence-Between-GMMs">Kullback-Leibler Divergence Between GMMs</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="priors.html">Priors in Gaussian Mixture Models</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">TorchGMM</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../source/tutorials.html">Tutorials</a></li>
      <li class="breadcrumb-item active">Clustering Metrics: Comprehensive Evaluation of Gaussian Mixture Models</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="Clustering-Metrics:-Comprehensive-Evaluation-of-Gaussian-Mixture-Models">
<h1>Clustering Metrics: Comprehensive Evaluation of Gaussian Mixture Models<a class="headerlink" href="#Clustering-Metrics:-Comprehensive-Evaluation-of-Gaussian-Mixture-Models" title="Link to this heading"></a></h1>
<p>This notebook provides a comprehensive evaluation of clustering performance using both <strong>unsupervised</strong> and <strong>supervised</strong> metrics. We demonstrate how to:</p>
<ol class="arabic simple">
<li><p><strong>Apply unsupervised metrics</strong> to determine the optimal number of components</p></li>
<li><p><strong>Compare supervised metrics</strong> with scikit-learn implementations</p></li>
<li><p><strong>Visualize clustering results</strong> with confusion matrices and classification reports</p></li>
<li><p><strong>Analyze KL divergence</strong> between different GMM models</p></li>
</ol>
<p>The notebook covers both theoretical foundations (with mathematical definitions) and practical implementations of clustering evaluation metrics.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>

<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="s1">&#39;../&#39;</span><span class="p">)</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">tgmm</span><span class="w"> </span><span class="kn">import</span> <span class="n">GaussianMixture</span><span class="p">,</span> <span class="n">ClusteringMetrics</span><span class="p">,</span> <span class="n">dynamic_figsize</span><span class="p">,</span> <span class="n">plot_gmm</span><span class="p">,</span> <span class="n">match_predicted_to_true_labels</span>

<span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span>
<span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>

<span class="k">if</span> <span class="n">device</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">:</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;CUDA version:&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">version</span><span class="o">.</span><span class="n">cuda</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Device:&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_name</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Using CPU&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
CUDA version: 12.4
Device: NVIDIA GeForce RTX 4060 Laptop GPU
</pre></div></div>
</div>
<section id="Synthetic-Data-Generation">
<h2>Synthetic Data Generation<a class="headerlink" href="#Synthetic-Data-Generation" title="Link to this heading"></a></h2>
<p>The synthetic dataset is generated by combining four Gaussian components:</p>
<ul class="simple">
<li><p><strong>Component 1:</strong> Centered at <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">2]</span></code> with spherical covariance.</p></li>
<li><p><strong>Component 2:</strong> Centered at <code class="docutils literal notranslate"><span class="pre">[2,</span> <span class="pre">-2]</span></code> with spherical covariance (fewer points).</p></li>
<li><p><strong>Component 3:</strong> Centered at <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">0]</span></code> with diagonal covariance.</p></li>
<li><p><strong>Component 4:</strong> Centered at <code class="docutils literal notranslate"><span class="pre">[2,</span> <span class="pre">2]</span></code> with full covariance.</p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[29]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_samples</span> <span class="o">=</span> <span class="p">[</span><span class="mi">800</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">]</span>
<span class="n">centers</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span>
           <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">]),</span>
           <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]),</span>
           <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])]</span>
<span class="n">covs</span> <span class="o">=</span> <span class="p">[</span>
    <span class="mf">1.0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span>                    <span class="c1"># spherical covariance</span>
    <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span>                    <span class="c1"># spherical covariance, fewer points</span>
    <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]]),</span>       <span class="c1"># diagonal covariance</span>
    <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>    <span class="c1"># full covariance</span>
<span class="p">]</span>

<span class="n">components</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">center</span><span class="p">,</span> <span class="n">cov</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">centers</span><span class="p">,</span> <span class="n">covs</span><span class="p">):</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">cov</span><span class="p">)</span> <span class="o">+</span> <span class="n">center</span>
    <span class="n">components</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">components</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">i</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)])</span>
<span class="n">legend_labels</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;Component </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">n_samples</span><span class="p">))]</span>

<span class="n">X_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">y_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

<span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">n_components</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>

<span class="n">plot_gmm</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">true_labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Original Data&#39;</span><span class="p">,</span> <span class="n">legend_labels</span><span class="o">=</span><span class="n">legend_labels</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_metrics_3_0.png" src="../_images/notebooks_metrics_3_0.png" />
</div>
</div>
</section>
<section id="Unsupervised-Clustering-Metrics-Definitions">
<h2>Unsupervised Clustering Metrics Definitions<a class="headerlink" href="#Unsupervised-Clustering-Metrics-Definitions" title="Link to this heading"></a></h2>
<p>Below are the definitions of the unsupervised clustering metrics used in this thesis.</p>
<section id="Silhouette-Score">
<h3>Silhouette Score<a class="headerlink" href="#Silhouette-Score" title="Link to this heading"></a></h3>
<p>The <strong>Silhouette Score</strong> quantifies how similar each data point is to its own cluster compared to other clusters. For a data point $ <span class="math">\mathbf{x}</span>_i $ belonging to cluster $ C_k $, the silhouette value is defined as</p>
<div class="math notranslate nohighlight">
\[s(i) = \frac{b(i) - a(i)}{\max\{a(i), b(i)\}},\]</div>
<p>where:</p>
<ul class="simple">
<li><p>$ a(i) $ is the average distance between <span class="math notranslate nohighlight">\(\mathbf{x}_i\)</span> and all other points in the same cluster $ C_k $ (i.e., the intra-cluster distance),</p></li>
<li><p>$ b(i) $ is the smallest average distance between <span class="math notranslate nohighlight">\(\mathbf{x}_i\)</span> and all points in any other cluster (i.e., the nearest-cluster distance).</p></li>
</ul>
<p>A high silhouette score (close to 1) indicates that the data point is well matched to its own cluster and poorly matched to neighboring clusters.</p>
</section>
<section id="Davies-Bouldin-Index">
<h3>Davies-Bouldin Index<a class="headerlink" href="#Davies-Bouldin-Index" title="Link to this heading"></a></h3>
<p>The <strong>Davies-Bouldin Index (DB)</strong> measures the average similarity between each cluster and its most similar one. It is defined as</p>
<div class="math notranslate nohighlight">
\[\text{DB} = \frac{1}{k} \sum_{i=1}^{k} \max_{j \neq i} \frac{S_i + S_j}{M_{ij}},\]</div>
<p>where:</p>
<ul class="simple">
<li><p>$ S_i $ is the average distance between the points in cluster $ i $ and the centroid of $ i $,</p></li>
<li><p>$ M_{ij} $ is the distance between the centroids of clusters $ i $ and $ j $.</p></li>
</ul>
<p>Lower values of the Davies-Bouldin Index indicate better clustering quality, as they reflect smaller within-cluster dispersion relative to the separation between clusters.</p>
</section>
<section id="Calinski-Harabasz-Score">
<h3>Calinski-Harabasz Score<a class="headerlink" href="#Calinski-Harabasz-Score" title="Link to this heading"></a></h3>
<p>The <strong>Calinski-Harabasz Score (CH)</strong> (also known as the Variance Ratio Criterion) is given by</p>
<div class="math notranslate nohighlight">
\[\text{CH} = \frac{n-k}{k-1}\cdot\frac{\sum _{i=1}^{k}n_{i}||\mathbf {c} _{i}-\mathbf {c} ||^{2}}{\sum _{i=1}^{k}\sum _{\mathbf {x} \in C_{i}}||\mathbf {x} -\mathbf {c} _{i}||^{2}},\]</div>
<p>where:</p>
<ul class="simple">
<li><p>$ k $ is the number of clusters,</p></li>
<li><p>$ n $ is the total number of samples.</p></li>
</ul>
<p>Higher Calinski-Harabasz scores suggest a model in which clusters are dense and well separated.</p>
</section>
<section id="Dunn-Index">
<h3>Dunn Index<a class="headerlink" href="#Dunn-Index" title="Link to this heading"></a></h3>
<p>The <strong>Dunn Index</strong> seeks to identify clusters that are both compact and well separated. It is defined as</p>
<div class="math notranslate nohighlight">
\[D = \frac{\min\limits_{i \neq j} d(C_i, C_j)}{\max\limits_{k} \mathrm{diam}(C_k)},\]</div>
<p>where:</p>
<ul class="simple">
<li><p>$ d(C_i, C_j) $ is the minimum distance between any two points in clusters $ C_i $ and $ C_j $,</p></li>
<li><p>$ :nbsphinx-math:<a href="#id1"><span class="problematic" id="id2">`</span></a>mathrm{diam}`(C_k) $ is the maximum distance between any two points in cluster $ C_k $.</p></li>
</ul>
<p>A higher Dunn Index indicates better clustering, meaning that the clusters are more compact and well separated.</p>
</section>
<section id="Bayesian-Information-Criterion-(BIC)">
<h3>Bayesian Information Criterion (BIC)<a class="headerlink" href="#Bayesian-Information-Criterion-(BIC)" title="Link to this heading"></a></h3>
<p>The <strong>Bayesian Information Criterion (BIC)</strong> is used for model selection by penalizing model complexity while rewarding goodness-of-fit. It is computed as</p>
<div class="math notranslate nohighlight">
\[\text{BIC} = n_{\text{params}} \cdot \ln(N) - 2 \cdot \mathcal{L},\]</div>
<p>where:</p>
<ul class="simple">
<li><p>$ n_{<span class="math">\text{params}</span>} $ is the number of free parameters in the model,</p></li>
<li><p>$ N $ is the number of samples,</p></li>
<li><p>$ <span class="math">\mathcal{L}</span> $ is the log-likelihood of the model.</p></li>
</ul>
<p>Lower BIC values indicate a model that better balances fit and simplicity.</p>
</section>
<section id="Akaike-Information-Criterion-(AIC)">
<h3>Akaike Information Criterion (AIC)<a class="headerlink" href="#Akaike-Information-Criterion-(AIC)" title="Link to this heading"></a></h3>
<p>The <strong>Akaike Information Criterion (AIC)</strong> is another metric for model selection defined as</p>
<div class="math notranslate nohighlight">
\[\text{AIC} = 2 \cdot n_{\text{params}} - 2 \cdot \mathcal{L}.\]</div>
<p>As with BIC, lower AIC values suggest a model that achieves a good trade-off between complexity and fit quality.</p>
<p><strong>Note:</strong> In practice, the ideal number of clusters is typically determined by seeking a maximum in the Silhouette Score, Calinski-Harabasz Score, and Dunn Index, while simultaneously looking for minima in the Davies-Bouldin Index, AIC, and BIC.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">components_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">11</span><span class="p">)</span>
<span class="n">silhouette_vals</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">components_range</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">davies_vals</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">components_range</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">calinski_vals</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">components_range</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">dunn_vals</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">components_range</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">bic_vals</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">components_range</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">aic_vals</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">components_range</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Fit a GMM for each n in components_range</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">components_range</span><span class="p">),</span> <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">components_range</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Evaluating range&quot;</span><span class="p">):</span>
    <span class="n">gmm</span> <span class="o">=</span> <span class="n">GaussianMixture</span><span class="p">(</span>
        <span class="n">n_features</span><span class="o">=</span><span class="n">n_features</span><span class="p">,</span>
        <span class="n">n_components</span><span class="o">=</span><span class="n">n</span><span class="p">,</span>
        <span class="n">covariance_type</span><span class="o">=</span><span class="s1">&#39;full&#39;</span><span class="p">,</span>
        <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">init_params</span><span class="o">=</span><span class="s1">&#39;kmeans&#39;</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
        <span class="n">tol</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span>
        <span class="n">reg_covar</span><span class="o">=</span><span class="mf">1e-7</span>
    <span class="p">)</span>
    <span class="c1"># Fit</span>
    <span class="n">gmm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_tensor</span><span class="p">)</span>
    <span class="n">labels_pred</span> <span class="o">=</span> <span class="n">gmm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_tensor</span><span class="p">)</span>  <span class="c1"># shape (N,)</span>

    <span class="c1"># Compute unsupervised metrics</span>
    <span class="n">silhouette_vals</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">ClusteringMetrics</span><span class="o">.</span><span class="n">silhouette_score</span><span class="p">(</span><span class="n">X_tensor</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
    <span class="n">davies_vals</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">ClusteringMetrics</span><span class="o">.</span><span class="n">davies_bouldin_index</span><span class="p">(</span><span class="n">X_tensor</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
    <span class="n">calinski_vals</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">ClusteringMetrics</span><span class="o">.</span><span class="n">calinski_harabasz_score</span><span class="p">(</span><span class="n">X_tensor</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
    <span class="n">dunn_vals</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">ClusteringMetrics</span><span class="o">.</span><span class="n">dunn_index</span><span class="p">(</span><span class="n">X_tensor</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
    <span class="n">bic_vals</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">ClusteringMetrics</span><span class="o">.</span><span class="n">bic_score</span><span class="p">(</span><span class="n">gmm</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_tensor</span><span class="p">),</span> <span class="n">X_tensor</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">gmm</span><span class="o">.</span><span class="n">covariance_type</span><span class="p">)</span>
    <span class="n">aic_vals</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">ClusteringMetrics</span><span class="o">.</span><span class="n">aic_score</span><span class="p">(</span><span class="n">gmm</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_tensor</span><span class="p">),</span> <span class="n">X_tensor</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">gmm</span><span class="o">.</span><span class="n">covariance_type</span><span class="p">)</span>

<span class="c1"># Compute the predicted ideal number of components for each metric</span>
<span class="n">sil_best</span> <span class="o">=</span> <span class="n">components_range</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">silhouette_vals</span><span class="p">)]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="n">davies_best</span> <span class="o">=</span> <span class="n">components_range</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">davies_vals</span><span class="p">)]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="n">calinski_best</span> <span class="o">=</span> <span class="n">components_range</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">calinski_vals</span><span class="p">)]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="n">dunn_best</span> <span class="o">=</span> <span class="n">components_range</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dunn_vals</span><span class="p">)]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="n">bic_best</span> <span class="o">=</span> <span class="n">components_range</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">bic_vals</span><span class="p">)]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="n">aic_best</span> <span class="o">=</span> <span class="n">components_range</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">aic_vals</span><span class="p">)]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

<span class="c1"># Create a 3-rows x 2-columns figure (3 rows, 2 columns)</span>
<span class="n">nrows</span><span class="p">,</span> <span class="n">ncols</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="p">,</span> <span class="n">ncols</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="n">dynamic_figsize</span><span class="p">(</span><span class="n">nrows</span><span class="p">,</span> <span class="n">ncols</span><span class="p">))</span>

<span class="c1"># 1) Silhouette Score (Row 1, Col 1)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">components_range</span><span class="p">,</span> <span class="n">silhouette_vals</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="s1">&#39;o-b&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">n_components</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;True # of Components&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">sil_best</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Predicted Ideal # of Components&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Silhouette Score&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Components&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Score&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">)</span>

<span class="c1"># 2) Davies-Bouldin Index (Row 1, Col 2)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">components_range</span><span class="p">,</span> <span class="n">davies_vals</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="s1">&#39;o-g&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">n_components</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;True # of Components&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">davies_best</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Predicted Ideal # of Components&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Davies-Bouldin Index&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Components&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">)</span>

<span class="c1"># 3) Calinski-Harabasz Score (Row 2, Col 1)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">components_range</span><span class="p">,</span> <span class="n">calinski_vals</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="s1">&#39;o-y&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">n_components</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;True # of Components&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">calinski_best</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Predicted Ideal # of Components&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Calinski-Harabasz Score&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Components&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">)</span>

<span class="c1"># 4) Dunn Index (Row 2, Col 2)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">components_range</span><span class="p">,</span> <span class="n">dunn_vals</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="s1">&#39;o-&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">n_components</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;True # of Components&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">dunn_best</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Predicted Ideal # of Components&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Dunn Index&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Components&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">)</span>

<span class="c1"># 5) BIC Score (Row 3, Col 1)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">components_range</span><span class="p">,</span> <span class="n">bic_vals</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="s1">&#39;o-m&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">n_components</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;True # of Components&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">bic_best</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Predicted Ideal # of Components&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;BIC Score&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Components&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">)</span>

<span class="c1"># 6) AIC Score (Row 3, Col 2)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">components_range</span><span class="p">,</span> <span class="n">aic_vals</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="s1">&#39;o-c&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">n_components</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;True # of Components&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">aic_best</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Predicted Ideal # of Components&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;AIC Score&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Components&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Unsupervised Clustering Metrics for a GMM&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">(</span><span class="n">rect</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">0.98</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=== Best Number of Components According to Each Metric ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Silhouette Best: </span><span class="si">{</span><span class="n">sil_best</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Davies-Bouldin Best (lowest): </span><span class="si">{</span><span class="n">davies_best</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Calinski-Harabasz Best: </span><span class="si">{</span><span class="n">calinski_best</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dunn Index Best: </span><span class="si">{</span><span class="n">dunn_best</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;BIC Best (lowest): </span><span class="si">{</span><span class="n">bic_best</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;AIC Best (lowest): </span><span class="si">{</span><span class="n">aic_best</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Evaluating range: 100%|██████████| 9/9 [00:00&lt;00:00, 12.44it/s]

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_metrics_5_1.png" src="../_images/notebooks_metrics_5_1.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
=== Best Number of Components According to Each Metric ===
Silhouette Best: 3
Davies-Bouldin Best (lowest): 4
Calinski-Harabasz Best: 3
Dunn Index Best: 5
BIC Best (lowest): 4
AIC Best (lowest): 4
</pre></div></div>
</div>
</section>
</section>
<section id="Supervised-Clustering-Metrics-Definitions">
<h2>Supervised Clustering Metrics Definitions<a class="headerlink" href="#Supervised-Clustering-Metrics-Definitions" title="Link to this heading"></a></h2>
<p>When ground truth labels are available, we can evaluate clustering performance using supervised metrics that measure the agreement between predicted and true cluster assignments.</p>
<section id="Rand-Index-(RI)">
<h3>Rand Index (RI)<a class="headerlink" href="#Rand-Index-(RI)" title="Link to this heading"></a></h3>
<p>The <strong>Rand Index</strong> measures the similarity between two clusterings by considering all pairs of samples and counting pairs that are assigned to the same or different clusters in both clusterings.</p>
<div class="math notranslate nohighlight">
\[\text{RI} = \frac{TP + TN}{TP + TN + FP + FN}\]</div>
<p>where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(TP\)</span> (True Positives): pairs that are in the same cluster in both clusterings</p></li>
<li><p><span class="math notranslate nohighlight">\(TN\)</span> (True Negatives): pairs that are in different clusters in both clusterings</p></li>
<li><p><span class="math notranslate nohighlight">\(FP\)</span> (False Positives): pairs that are in the same cluster in predicted but different clusters in true</p></li>
<li><p><span class="math notranslate nohighlight">\(FN\)</span> (False Negatives): pairs that are in different clusters in predicted but same cluster in true</p></li>
</ul>
<p>The Rand Index ranges from 0 to 1, where 1 indicates perfect agreement.</p>
</section>
<section id="Adjusted-Rand-Index-(ARI)">
<h3>Adjusted Rand Index (ARI)<a class="headerlink" href="#Adjusted-Rand-Index-(ARI)" title="Link to this heading"></a></h3>
<p>The <strong>Adjusted Rand Index</strong> corrects the Rand Index for chance by subtracting the expected value and normalizing by the maximum possible value:</p>
<div class="math notranslate nohighlight">
\[\text{ARI} = \frac{\text{RI} - \mathbb{E}[\text{RI}]}{\max(\text{RI}) - \mathbb{E}[\text{RI}]}\]</div>
<p>More explicitly, using the contingency table approach:</p>
<div class="math notranslate nohighlight">
\[\text{ARI} = \frac{\sum_{ij} \binom{n_{ij}}{2} - \left[\sum_i \binom{a_i}{2} \sum_j \binom{b_j}{2}\right] / \binom{n}{2}}{\frac{1}{2}\left[\sum_i \binom{a_i}{2} + \sum_j \binom{b_j}{2}\right] - \left[\sum_i \binom{a_i}{2} \sum_j \binom{b_j}{2}\right] / \binom{n}{2}}\]</div>
<p>where <span class="math notranslate nohighlight">\(n_{ij}\)</span> is the number of samples in cluster <span class="math notranslate nohighlight">\(i\)</span> of the true clustering and cluster <span class="math notranslate nohighlight">\(j\)</span> of the predicted clustering. ARI ranges from -1 to 1, with 1 indicating perfect agreement and 0 indicating random labeling.</p>
</section>
<section id="Mutual-Information-(MI)">
<h3>Mutual Information (MI)<a class="headerlink" href="#Mutual-Information-(MI)" title="Link to this heading"></a></h3>
<p><strong>Mutual Information</strong> measures the amount of information obtained about one clustering by observing the other:</p>
<div class="math notranslate nohighlight">
\[\text{MI}(U,V) = \sum_{i=1}^{|U|} \sum_{j=1}^{|V|} P(i,j) \log\frac{P(i,j)}{P(i)P(j)}\]</div>
<p>where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(U\)</span> and <span class="math notranslate nohighlight">\(V\)</span> are the true and predicted clusterings</p></li>
<li><p><span class="math notranslate nohighlight">\(P(i,j) = \frac{|U_i \cap V_j|}{N}\)</span> is the probability that a point belongs to clusters <span class="math notranslate nohighlight">\(U_i\)</span> and <span class="math notranslate nohighlight">\(V_j\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P(i) = \frac{|U_i|}{N}\)</span> and <span class="math notranslate nohighlight">\(P(j) = \frac{|V_j|}{N}\)</span> are marginal probabilities</p></li>
</ul>
</section>
<section id="Normalized-Mutual-Information-(NMI)">
<h3>Normalized Mutual Information (NMI)<a class="headerlink" href="#Normalized-Mutual-Information-(NMI)" title="Link to this heading"></a></h3>
<p><strong>Normalized Mutual Information</strong> scales MI to the range [0,1] by normalizing with the entropy of the clusterings:</p>
<div class="math notranslate nohighlight">
\[\text{NMI}(U,V) = \frac{2 \times \text{MI}(U,V)}{H(U) + H(V)}\]</div>
<p>where <span class="math notranslate nohighlight">\(H(U) = -\sum_{i=1}^{|U|} P(i) \log P(i)\)</span> is the entropy of clustering <span class="math notranslate nohighlight">\(U\)</span>.</p>
</section>
<section id="Adjusted-Mutual-Information-(AMI)">
<h3>Adjusted Mutual Information (AMI)<a class="headerlink" href="#Adjusted-Mutual-Information-(AMI)" title="Link to this heading"></a></h3>
<p><strong>Adjusted Mutual Information</strong> corrects MI for chance, similar to how ARI corrects RI:</p>
<div class="math notranslate nohighlight">
\[\text{AMI}(U,V) = \frac{\text{MI}(U,V) - \mathbb{E}[\text{MI}(U,V)]}{\max(H(U), H(V)) - \mathbb{E}[\text{MI}(U,V)]}\]</div>
</section>
<section id="Fowlkes-Mallows-Index-(FMI)">
<h3>Fowlkes-Mallows Index (FMI)<a class="headerlink" href="#Fowlkes-Mallows-Index-(FMI)" title="Link to this heading"></a></h3>
<p>The <strong>Fowlkes-Mallows Index</strong> is the geometric mean of pairwise precision and recall:</p>
<div class="math notranslate nohighlight">
\[\text{FMI} = \sqrt{\frac{TP}{TP + FP} \times \frac{TP}{TP + FN}} = \sqrt{\text{Precision} \times \text{Recall}}\]</div>
<p>where TP, FP, and FN are defined as in the Rand Index but for pairwise comparisons.</p>
</section>
<section id="Homogeneity-and-Completeness">
<h3>Homogeneity and Completeness<a class="headerlink" href="#Homogeneity-and-Completeness" title="Link to this heading"></a></h3>
<p><strong>Homogeneity</strong> measures whether each cluster contains only members of a single class:</p>
<div class="math notranslate nohighlight">
\[h = 1 - \frac{H(C|K)}{H(C)}\]</div>
<p><strong>Completeness</strong> measures whether all members of a given class are assigned to the same cluster:</p>
<div class="math notranslate nohighlight">
\[c = 1 - \frac{H(K|C)}{H(K)}\]</div>
<p>where <span class="math notranslate nohighlight">\(H(C|K)\)</span> is the conditional entropy of the true classes given the cluster assignments.</p>
</section>
<section id="V-Measure">
<h3>V-Measure<a class="headerlink" href="#V-Measure" title="Link to this heading"></a></h3>
<p>The <strong>V-Measure</strong> is the harmonic mean of homogeneity and completeness:</p>
<div class="math notranslate nohighlight">
\[\text{V} = \frac{2 \times h \times c}{h + c}\]</div>
</section>
<section id="Purity">
<h3>Purity<a class="headerlink" href="#Purity" title="Link to this heading"></a></h3>
<p><strong>Purity</strong> measures the extent to which clusters contain a single class:</p>
<div class="math notranslate nohighlight">
\[\text{Purity} = \frac{1}{N} \sum_{k=1}^{K} \max_j |C_k \cap T_j|\]</div>
<p>where <span class="math notranslate nohighlight">\(C_k\)</span> is the set of samples in cluster <span class="math notranslate nohighlight">\(k\)</span> and <span class="math notranslate nohighlight">\(T_j\)</span> is the set of samples in true class <span class="math notranslate nohighlight">\(j\)</span>.</p>
<p><strong>Interpretation Guidelines:</strong></p>
<ul class="simple">
<li><p><strong>Higher is better</strong>: RI, ARI, MI, NMI, AMI, FMI, Homogeneity, Completeness, V-Measure, Purity</p></li>
<li><p><strong>Range [0,1]</strong>: Most metrics except ARI which can be negative</p></li>
<li><p><strong>Perfect clustering</strong>: All metrics = 1 (except ARI where perfect = 1, random ≈ 0)</p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[31]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Scikit-learn for comparison</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.mixture</span><span class="w"> </span><span class="kn">import</span> <span class="n">GaussianMixture</span> <span class="k">as</span> <span class="n">SklearnGMM</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.decomposition</span><span class="w"> </span><span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">silhouette_score</span><span class="p">,</span>
    <span class="n">davies_bouldin_score</span><span class="p">,</span>
    <span class="n">calinski_harabasz_score</span><span class="p">,</span>
    <span class="n">adjusted_rand_score</span><span class="p">,</span>
    <span class="n">normalized_mutual_info_score</span><span class="p">,</span>
    <span class="n">fowlkes_mallows_score</span><span class="p">,</span>
    <span class="n">homogeneity_score</span><span class="p">,</span>
    <span class="n">mutual_info_score</span><span class="p">,</span>
    <span class="n">adjusted_mutual_info_score</span><span class="p">,</span>
    <span class="n">completeness_score</span><span class="p">,</span>
    <span class="n">v_measure_score</span><span class="p">,</span>
    <span class="n">rand_score</span>
<span class="p">)</span>

<span class="n">gmm</span> <span class="o">=</span> <span class="n">GaussianMixture</span><span class="p">(</span>
    <span class="n">n_features</span><span class="o">=</span><span class="n">n_features</span><span class="p">,</span>
    <span class="n">n_components</span><span class="o">=</span><span class="n">n_components</span><span class="p">,</span>
    <span class="n">covariance_type</span><span class="o">=</span><span class="s1">&#39;full&#39;</span><span class="p">,</span>
    <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">init_params</span><span class="o">=</span><span class="s1">&#39;kmeans&#39;</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="n">device</span>
<span class="p">)</span>
<span class="n">gmm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_tensor</span><span class="p">)</span>
<span class="n">labels_pred</span> <span class="o">=</span> <span class="n">gmm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_tensor</span><span class="p">)</span>

<span class="c1"># Metrics with custom ClusteringMetrics</span>
<span class="n">metrics_to_compare</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;rand_score&quot;</span><span class="p">,</span>
    <span class="s2">&quot;adjusted_rand_score&quot;</span><span class="p">,</span>
    <span class="s2">&quot;mutual_info_score&quot;</span><span class="p">,</span>
    <span class="s2">&quot;normalized_mutual_info_score&quot;</span><span class="p">,</span>
    <span class="s2">&quot;adjusted_mutual_info_score&quot;</span><span class="p">,</span>
    <span class="s2">&quot;fowlkes_mallows_score&quot;</span><span class="p">,</span>
    <span class="s2">&quot;homogeneity_score&quot;</span><span class="p">,</span>
    <span class="s2">&quot;completeness_score&quot;</span><span class="p">,</span>
    <span class="s2">&quot;v_measure_score&quot;</span><span class="p">,</span>
    <span class="s2">&quot;silhouette_score&quot;</span><span class="p">,</span>
    <span class="s2">&quot;davies_bouldin_index&quot;</span><span class="p">,</span>
    <span class="s2">&quot;calinski_harabasz_score&quot;</span><span class="p">,</span>
    <span class="s2">&quot;purity_score&quot;</span><span class="p">,</span>   <span class="c1"># Torch-only metric</span>
    <span class="s2">&quot;dunn_index&quot;</span><span class="p">,</span>     <span class="c1"># Torch-only metric</span>
    <span class="s2">&quot;bic_score&quot;</span><span class="p">,</span>      <span class="c1"># Compare Torch vs Sklearn BIC</span>
    <span class="s2">&quot;aic_score&quot;</span><span class="p">,</span>      <span class="c1"># Compare Torch vs Sklearn AIC</span>
<span class="p">]</span>
<span class="n">scores_torch</span> <span class="o">=</span> <span class="n">ClusteringMetrics</span><span class="o">.</span><span class="n">evaluate_clustering</span><span class="p">(</span>
    <span class="n">gmm</span><span class="p">,</span>
    <span class="n">X_tensor</span><span class="p">,</span>
    <span class="n">true_labels</span><span class="o">=</span><span class="n">y_tensor</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="n">metrics_to_compare</span>
<span class="p">)</span>

<span class="c1"># Compare with sklearn</span>
<span class="n">X_np</span> <span class="o">=</span> <span class="n">X_tensor</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">y_np</span> <span class="o">=</span> <span class="n">y_tensor</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">labels_pred_np</span> <span class="o">=</span> <span class="n">labels_pred</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">sk_gmm</span> <span class="o">=</span> <span class="n">SklearnGMM</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">n_components</span><span class="p">,</span> <span class="n">covariance_type</span><span class="o">=</span><span class="s1">&#39;full&#39;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">init_params</span><span class="o">=</span><span class="s1">&#39;kmeans&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">reg_covar</span><span class="o">=</span><span class="mf">1e-7</span><span class="p">)</span>
<span class="n">sk_gmm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_np</span><span class="p">)</span>

<span class="n">scores_sklearn</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;rand_score&quot;</span><span class="p">:</span> <span class="n">rand_score</span><span class="p">(</span><span class="n">y_np</span><span class="p">,</span> <span class="n">labels_pred_np</span><span class="p">),</span>
    <span class="s2">&quot;adjusted_rand_score&quot;</span><span class="p">:</span> <span class="n">adjusted_rand_score</span><span class="p">(</span><span class="n">y_np</span><span class="p">,</span> <span class="n">labels_pred_np</span><span class="p">),</span>
    <span class="s2">&quot;mutual_info_score&quot;</span><span class="p">:</span> <span class="n">mutual_info_score</span><span class="p">(</span><span class="n">y_np</span><span class="p">,</span> <span class="n">labels_pred_np</span><span class="p">),</span>
    <span class="s2">&quot;normalized_mutual_info_score&quot;</span><span class="p">:</span> <span class="n">normalized_mutual_info_score</span><span class="p">(</span><span class="n">y_np</span><span class="p">,</span> <span class="n">labels_pred_np</span><span class="p">),</span>
    <span class="s2">&quot;adjusted_mutual_info_score&quot;</span><span class="p">:</span> <span class="n">adjusted_mutual_info_score</span><span class="p">(</span><span class="n">y_np</span><span class="p">,</span> <span class="n">labels_pred_np</span><span class="p">),</span>
    <span class="s2">&quot;fowlkes_mallows_score&quot;</span><span class="p">:</span> <span class="n">fowlkes_mallows_score</span><span class="p">(</span><span class="n">y_np</span><span class="p">,</span> <span class="n">labels_pred_np</span><span class="p">),</span>
    <span class="s2">&quot;homogeneity_score&quot;</span><span class="p">:</span> <span class="n">homogeneity_score</span><span class="p">(</span><span class="n">y_np</span><span class="p">,</span> <span class="n">labels_pred_np</span><span class="p">),</span>
    <span class="s2">&quot;completeness_score&quot;</span><span class="p">:</span> <span class="n">completeness_score</span><span class="p">(</span><span class="n">y_np</span><span class="p">,</span> <span class="n">labels_pred_np</span><span class="p">),</span>
    <span class="s2">&quot;v_measure_score&quot;</span><span class="p">:</span> <span class="n">v_measure_score</span><span class="p">(</span><span class="n">y_np</span><span class="p">,</span> <span class="n">labels_pred_np</span><span class="p">),</span>
    <span class="s2">&quot;silhouette_score&quot;</span><span class="p">:</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">X_np</span><span class="p">,</span> <span class="n">labels_pred_np</span><span class="p">),</span>
    <span class="s2">&quot;davies_bouldin_index&quot;</span><span class="p">:</span> <span class="n">davies_bouldin_score</span><span class="p">(</span><span class="n">X_np</span><span class="p">,</span> <span class="n">labels_pred_np</span><span class="p">),</span>
    <span class="s2">&quot;calinski_harabasz_score&quot;</span><span class="p">:</span> <span class="n">calinski_harabasz_score</span><span class="p">(</span><span class="n">X_np</span><span class="p">,</span> <span class="n">labels_pred_np</span><span class="p">),</span>
<span class="p">}</span>
<span class="n">sk_bic</span> <span class="o">=</span> <span class="n">sk_gmm</span><span class="o">.</span><span class="n">bic</span><span class="p">(</span><span class="n">X_np</span><span class="p">)</span>
<span class="n">sk_aic</span> <span class="o">=</span> <span class="n">sk_gmm</span><span class="o">.</span><span class="n">aic</span><span class="p">(</span><span class="n">X_np</span><span class="p">)</span>



<span class="n">rows</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="n">metrics_to_compare</span><span class="p">:</span>
    <span class="c1"># Retrieve the Torch metric score if available.</span>
    <span class="n">torch_val</span> <span class="o">=</span> <span class="n">scores_torch</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">metric</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="c1"># Retrieve the scikit-learn metric score if available.</span>
    <span class="k">if</span> <span class="n">metric</span> <span class="ow">in</span> <span class="n">scores_sklearn</span><span class="p">:</span>
        <span class="n">sklearn_val</span> <span class="o">=</span> <span class="n">scores_sklearn</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">metric</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">metric</span> <span class="o">==</span> <span class="s2">&quot;bic_score&quot;</span><span class="p">:</span>
        <span class="n">sklearn_val</span> <span class="o">=</span> <span class="n">sk_bic</span>
    <span class="k">elif</span> <span class="n">metric</span> <span class="o">==</span> <span class="s2">&quot;aic_score&quot;</span><span class="p">:</span>
        <span class="n">sklearn_val</span> <span class="o">=</span> <span class="n">sk_aic</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">sklearn_val</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># Calculate the absolute difference and the relative difference in percent.</span>
    <span class="k">if</span> <span class="n">torch_val</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">sklearn_val</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">abs_diff</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">torch_val</span> <span class="o">-</span> <span class="n">sklearn_val</span><span class="p">)</span>
        <span class="c1"># Avoid division by zero; if sklearn_val is zero, set relative difference to None.</span>
        <span class="n">rel_diff</span> <span class="o">=</span> <span class="p">(</span><span class="n">abs_diff</span> <span class="o">/</span> <span class="nb">abs</span><span class="p">(</span><span class="n">sklearn_val</span><span class="p">))</span> <span class="o">*</span> <span class="mi">100</span> <span class="k">if</span> <span class="n">sklearn_val</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">else</span> <span class="kc">None</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">abs_diff</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">rel_diff</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="n">rows</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
        <span class="s2">&quot;Metric&quot;</span><span class="p">:</span> <span class="n">metric</span><span class="p">,</span>
        <span class="s2">&quot;Torch Score&quot;</span><span class="p">:</span> <span class="n">torch_val</span><span class="p">,</span>
        <span class="s2">&quot;Sklearn Score&quot;</span><span class="p">:</span> <span class="n">sklearn_val</span><span class="p">,</span>
        <span class="s2">&quot;Absolute Difference&quot;</span><span class="p">:</span> <span class="n">abs_diff</span><span class="p">,</span>
        <span class="s2">&quot;Relative Difference (%)&quot;</span><span class="p">:</span> <span class="n">rel_diff</span>
    <span class="p">})</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plot_gmm</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_np</span><span class="p">,</span> <span class="n">gmm</span><span class="o">=</span><span class="n">gmm</span><span class="p">,</span> <span class="n">true_labels</span><span class="o">=</span><span class="n">y_tensor</span><span class="p">,</span> <span class="n">match_labels_to_true</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;GMM Predictions&#39;</span><span class="p">,</span> <span class="n">show_ellipses</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">show_incorrect_predictions</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ellipse_fill</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ellipse_std_devs</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">point_size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_metrics_7_0.png" src="../_images/notebooks_metrics_7_0.png" />
</div>
</div>
</section>
</section>
<section id="Model-Comparison:-TorchGMM-vs-Scikit-learn">
<h2>Model Comparison: TorchGMM vs Scikit-learn<a class="headerlink" href="#Model-Comparison:-TorchGMM-vs-Scikit-learn" title="Link to this heading"></a></h2>
<p>This section compares the clustering metrics computed by our TorchGMM implementation with scikit-learn’s implementations to validate correctness and highlight any differences in computation methods.</p>
<section id="Metrics-Comparison-Table">
<h3>Metrics Comparison Table<a class="headerlink" href="#Metrics-Comparison-Table" title="Link to this heading"></a></h3>
<p>The table below shows side-by-side comparisons of metrics computed using both implementations. Small differences may occur due to:</p>
<ul class="simple">
<li><p>Different numerical precision</p></li>
<li><p>Slightly different algorithmic implementations</p></li>
<li><p>Different handling of edge cases (e.g., single-point clusters)</p></li>
</ul>
<p><strong>Key observations:</strong></p>
<ul class="simple">
<li><p><strong>Information-theoretic metrics</strong> (MI, NMI, AMI) should be very close</p></li>
<li><p><strong>Pairwise metrics</strong> (RI, ARI, FMI) should match exactly for identical cluster assignments</p></li>
<li><p><strong>Geometric metrics</strong> (Silhouette, Davies-Bouldin, Calinski-Harabasz) may show small differences due to distance computation methods</p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[32]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_metrics</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">rows</span><span class="p">)</span>
<span class="n">df_metrics</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[32]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Metric</th>
      <th>Torch Score</th>
      <th>Sklearn Score</th>
      <th>Absolute Difference</th>
      <th>Relative Difference (%)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>rand_score</td>
      <td>0.922936</td>
      <td>0.922936</td>
      <td>7.921422e-09</td>
      <td>8.582850e-07</td>
    </tr>
    <tr>
      <th>1</th>
      <td>adjusted_rand_score</td>
      <td>0.816571</td>
      <td>0.816571</td>
      <td>9.265805e-09</td>
      <td>1.134721e-06</td>
    </tr>
    <tr>
      <th>2</th>
      <td>mutual_info_score</td>
      <td>0.980560</td>
      <td>0.980560</td>
      <td>2.375290e-08</td>
      <td>2.422381e-06</td>
    </tr>
    <tr>
      <th>3</th>
      <td>normalized_mutual_info_score</td>
      <td>0.778043</td>
      <td>0.778043</td>
      <td>1.091963e-07</td>
      <td>1.403475e-05</td>
    </tr>
    <tr>
      <th>4</th>
      <td>adjusted_mutual_info_score</td>
      <td>0.777949</td>
      <td>0.777777</td>
      <td>1.721395e-04</td>
      <td>2.213223e-02</td>
    </tr>
    <tr>
      <th>5</th>
      <td>fowlkes_mallows_score</td>
      <td>0.871655</td>
      <td>0.871655</td>
      <td>3.285231e-08</td>
      <td>3.768957e-06</td>
    </tr>
    <tr>
      <th>6</th>
      <td>homogeneity_score</td>
      <td>0.773056</td>
      <td>0.774893</td>
      <td>1.837321e-03</td>
      <td>2.371064e-01</td>
    </tr>
    <tr>
      <th>7</th>
      <td>completeness_score</td>
      <td>0.782989</td>
      <td>0.781218</td>
      <td>1.771340e-03</td>
      <td>2.267408e-01</td>
    </tr>
    <tr>
      <th>8</th>
      <td>v_measure_score</td>
      <td>0.777991</td>
      <td>0.778043</td>
      <td>5.184373e-05</td>
      <td>6.663353e-03</td>
    </tr>
    <tr>
      <th>9</th>
      <td>silhouette_score</td>
      <td>0.184356</td>
      <td>0.184356</td>
      <td>4.470348e-08</td>
      <td>2.424840e-05</td>
    </tr>
    <tr>
      <th>10</th>
      <td>davies_bouldin_index</td>
      <td>1.252130</td>
      <td>1.252130</td>
      <td>1.186502e-07</td>
      <td>9.475868e-06</td>
    </tr>
    <tr>
      <th>11</th>
      <td>calinski_harabasz_score</td>
      <td>701.308289</td>
      <td>701.308533</td>
      <td>2.441406e-04</td>
      <td>3.481216e-05</td>
    </tr>
    <tr>
      <th>12</th>
      <td>purity_score</td>
      <td>0.931000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>13</th>
      <td>dunn_index</td>
      <td>0.002177</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>14</th>
      <td>bic_score</td>
      <td>19292.576172</td>
      <td>19292.308851</td>
      <td>2.673210e-01</td>
      <td>1.385635e-03</td>
    </tr>
    <tr>
      <th>15</th>
      <td>aic_score</td>
      <td>19154.428955</td>
      <td>19154.162397</td>
      <td>2.665582e-01</td>
      <td>1.391646e-03</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
</section>
</section>
<section id="Confusion-Matrix-and-Classification-Report">
<h2>Confusion Matrix and Classification Report<a class="headerlink" href="#Confusion-Matrix-and-Classification-Report" title="Link to this heading"></a></h2>
<section id="Understanding-the-Confusion-Matrix">
<h3>Understanding the Confusion Matrix<a class="headerlink" href="#Understanding-the-Confusion-Matrix" title="Link to this heading"></a></h3>
<p>The confusion matrix provides a detailed breakdown of correct and incorrect predictions for each class. Before computing the matrix, we use <strong>label matching</strong> to align predicted cluster labels with true class labels, as clustering algorithms may assign arbitrary label numbers.</p>
<p><strong>Key metrics derived from the confusion matrix:</strong></p>
<ul class="simple">
<li><p><strong>Precision</strong>: <span class="math notranslate nohighlight">\(\frac{TP}{TP + FP}\)</span> - What fraction of predicted positives are actually positive?</p></li>
<li><p><strong>Recall</strong>: <span class="math notranslate nohighlight">\(\frac{TP}{TP + FN}\)</span> - What fraction of actual positives are correctly predicted?</p></li>
<li><p><strong>F1-Score</strong>: <span class="math notranslate nohighlight">\(\frac{2 \times \text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}\)</span> - Harmonic mean of precision and recall</p></li>
<li><p><strong>Support</strong>: Number of true instances for each class</p></li>
</ul>
<p>The heatmap below shows the confusion matrix as percentages, normalized by the true class sizes.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[33]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get matched predictions</span>
<span class="n">matched_pred</span> <span class="o">=</span> <span class="n">match_predicted_to_true_labels</span><span class="p">(</span><span class="n">y_tensor</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>

<span class="c1"># Compute confusion matrix using ClusteringMetrics.confusion_matrix</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">ClusteringMetrics</span><span class="o">.</span><span class="n">confusion_matrix</span><span class="p">(</span>
    <span class="n">y_tensor</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">),</span>
    <span class="n">matched_pred</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Convert the confusion matrix to percentages (normalize per true label)</span>
<span class="n">cm_np</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
<span class="n">cm_percent</span> <span class="o">=</span> <span class="p">(</span><span class="n">cm_np</span><span class="o">.</span><span class="n">T</span> <span class="o">/</span> <span class="n">cm_np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">T</span> <span class="o">*</span> <span class="mi">100</span>

<span class="c1"># Plot heatmap of the percent confusion matrix</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm_percent</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;.1f&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Blues&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix (%)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Predicted Label&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;True Label&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Generate classification report</span>
<span class="n">report</span> <span class="o">=</span> <span class="n">ClusteringMetrics</span><span class="o">.</span><span class="n">classification_report</span><span class="p">(</span>
    <span class="n">y_tensor</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">),</span>
    <span class="n">matched_pred</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Convert classification report to a DataFrame for display</span>
<span class="n">report_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">report</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
<span class="n">report_df</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_metrics_11_0.png" src="../_images/notebooks_metrics_11_0.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[33]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>precision</th>
      <th>recall</th>
      <th>f1-score</th>
      <th>support</th>
      <th>jaccard</th>
      <th>roc_auc</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.951923</td>
      <td>0.86625</td>
      <td>0.907068</td>
      <td>800.0</td>
      <td>0.829940</td>
      <td>0.997872</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.969072</td>
      <td>0.94000</td>
      <td>0.954315</td>
      <td>200.0</td>
      <td>0.912621</td>
      <td>0.982729</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.898058</td>
      <td>0.92500</td>
      <td>0.911330</td>
      <td>1000.0</td>
      <td>0.837104</td>
      <td>0.917763</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.941794</td>
      <td>0.98700</td>
      <td>0.963867</td>
      <td>1000.0</td>
      <td>0.930254</td>
      <td>0.956896</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
</section>
</section>
<section id="KL-Divergence-Analysis">
<h2>KL Divergence Analysis<a class="headerlink" href="#KL-Divergence-Analysis" title="Link to this heading"></a></h2>
<section id="Kullback-Leibler-Divergence-Between-GMMs">
<h3>Kullback-Leibler Divergence Between GMMs<a class="headerlink" href="#Kullback-Leibler-Divergence-Between-GMMs" title="Link to this heading"></a></h3>
<p>The <strong>KL divergence</strong> <span class="math notranslate nohighlight">\(D_{KL}(P \parallel Q)\)</span> measures how one probability distribution <span class="math notranslate nohighlight">\(P\)</span> diverges from a reference distribution <span class="math notranslate nohighlight">\(Q\)</span>:</p>
<div class="math notranslate nohighlight">
\[D_{KL}(P \parallel Q) = \int p(x) \log \frac{p(x)}{q(x)} dx\]</div>
<p>For Gaussian Mixture Models, we approximate this using Monte Carlo sampling:</p>
<div class="math notranslate nohighlight">
\[D_{KL}(P \parallel Q) \approx \frac{1}{N} \sum_{i=1}^{N} \left[ \log p(x_i) - \log q(x_i) \right]\]</div>
<p>where <span class="math notranslate nohighlight">\(x_i \sim P\)</span> are samples drawn from the first GMM.</p>
<p><strong>Interpretation:</strong></p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(D_{KL}(P \parallel Q) = 0\)</span> when <span class="math notranslate nohighlight">\(P = Q\)</span> (identical distributions)</p></li>
<li><p><span class="math notranslate nohighlight">\(D_{KL}(P \parallel Q) &gt; 0\)</span> always (non-negative)</p></li>
<li><p><strong>Asymmetric</strong>: <span class="math notranslate nohighlight">\(D_{KL}(P \parallel Q) \neq D_{KL}(Q \parallel P)\)</span> in general</p></li>
<li><p><strong>Lower values</strong> indicate more similar distributions</p></li>
</ul>
<p>The plot below shows how KL divergence changes as we vary the number of components in the test GMM while keeping the reference GMM fixed at the true number of components.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[34]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">RUN_KL_DIVERGENCE</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">if</span> <span class="n">RUN_KL_DIVERGENCE</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Computing KL(p||q) for different numbers of components...&quot;</span><span class="p">)</span>
    <span class="n">gmm_true</span> <span class="o">=</span> <span class="n">GaussianMixture</span><span class="p">(</span>
        <span class="n">n_features</span><span class="o">=</span><span class="n">n_features</span><span class="p">,</span>
        <span class="n">n_components</span><span class="o">=</span><span class="n">n_components</span><span class="p">,</span>
        <span class="n">covariance_type</span><span class="o">=</span><span class="s1">&#39;full&#39;</span><span class="p">,</span>
        <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">init_params</span><span class="o">=</span><span class="s1">&#39;kmeans&#39;</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">device</span>
    <span class="p">)</span>
    <span class="n">gmm_true</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_tensor</span><span class="p">)</span>

    <span class="n">test_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>
    <span class="n">kl_vals</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_range</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">test_range</span><span class="p">),</span> <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">test_range</span><span class="p">)):</span>
        <span class="n">gmm_test</span> <span class="o">=</span> <span class="n">GaussianMixture</span><span class="p">(</span>
            <span class="n">n_features</span><span class="o">=</span><span class="n">n_features</span><span class="p">,</span>
            <span class="n">n_components</span><span class="o">=</span><span class="n">n</span><span class="p">,</span>
            <span class="n">covariance_type</span><span class="o">=</span><span class="s1">&#39;full&#39;</span><span class="p">,</span>
            <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
            <span class="n">init_params</span><span class="o">=</span><span class="s1">&#39;kmeans&#39;</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">device</span>
        <span class="p">)</span>
        <span class="n">gmm_test</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_tensor</span><span class="p">)</span>

        <span class="n">kl_vals</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">ClusteringMetrics</span><span class="o">.</span><span class="n">kl_divergence_gmm</span><span class="p">(</span><span class="n">gmm_true</span><span class="p">,</span> <span class="n">gmm_test</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">test_range</span><span class="p">,</span> <span class="n">kl_vals</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;KL Divergence: True GMM vs. Various n_components&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Number of Components&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;KL Divergence (log scale)&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Computing KL(p||q) for different numbers of components...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
100%|██████████| 14/14 [00:01&lt;00:00, 12.63it/s]

</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_metrics_13_2.png" src="../_images/notebooks_metrics_13_2.png" />
</div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="gmm.html" class="btn btn-neutral float-left" title="Gaussian Mixture Model (GMM) Usage, Analysis and Visualization" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="priors.html" class="btn btn-neutral float-right" title="Priors in Gaussian Mixture Models" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Adrián A. Sousa-Poza.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>